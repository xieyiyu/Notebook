## 项目经历
1. 项目业务背景、 目的（包装一个高大上的背景及目的）
2. 效果，完成到哪一步，取得什么效果
3. 流程及技术细节，分步骤，可以将每个步骤用的技术和遇到的困难讲一下，也可以加入自己的感悟，但不要一概而过
4. 目前存在的问题，可以怎么去优化

明白简历中存在的知识盲区，并提前想好应对对策。


### CCKS2018 评测：中文电子病历命名实体识别
CCKS2018:全国知识图谱与语义计算大会，评测任务  
- 要求：抽取出中文电子病历中的五类实体，包括解剖部位、症状描述、独立症状、药品和手术
- 方法：基于 双向长短时记忆神经网络和条件随机场(Bi-LSTM-CRF) 方法，基于字为单元训练，采用 BIOES 方法标记实体边界，最后用外部字典来优化手术和药品两类实体的效果。
- 结果： F1值达到 83.19%，排名中间(34/73)，与第一名相差 6%

1. 得到 Bi-LSTM-CRF 的输入数据，基于字为单元训练，采用 BIOES 标记实体边界
2. 使用 word2vec 训练 100 维词向量
3. 得到训练模型
4. 用模型预测测试集结果，得到结果
5. 对结果进行优化

目的：为了拿到数据，同时锻炼一下自己的能力

#### Bi-LSTM-CRF
主要是分三层，由下到上分别为： Word Embedding层、 Bi-LSTM层、 CRF层

**深度学习处理序列标注问题**  
将 token 从离散 one-hot 表示映射到低维空间中成为稠密的 embedding，随后将句子的 embedding 序列输入到 RNN 中，用神经网络自动提取特征，Softmax 来预测每个 token 的标签。  
优：不依赖特征工程，是数据驱动的方法。  
缺：种类繁多，对参数设置依赖大，模型可解释性差。

**Bi-LSTM 优势**  
同时考虑了过去的特征（通过前向过程提取）和未来的特征（通过后项过程提取）。后项过程相当于将原始序列逆向输入到 LSTM 中，Bi-LSTM 相当于两个 LSTM，一个正向输入序列，一个反向输入序列，再将两者的输出结果结合起来作为最终的结果。

**为什么要后面接 CRF 方法？**  
CRF 是为获取全局最优的输出序列，相当于对 LSTM 信息的再利用。

Bi-LSTM 预测标注可能出现问题，如 B 后面再接一个 B，套接 CRF 后不会出现这种情况。因为 CRF 的特征函数和特征模板的存在就是为了对给定序列观察学习各种特征，特征就是在限定窗口 size 下的各词之间的关系，一般都能学到这样的特征，B 后面不能接 B

从网络结构上看，Bi-LSTM-CRF 套用的还是 CRF 大框架，只是把 LSTM 在每个时刻 t 在第 i 个 tag 上的输出，看做是 CRF 特征函数里的点函数（即只与当前位置有关的特征函数），而边函数（与前后位置有关的特征函数）仍是 CRF 自带的。这样就将线性 CRF 里的原始的线性特征函数变为了 LSTM 里的非线性函数，可以获得更好的拟合。


**学到的内容：**
1. 

**遇到的困难：**
1. 对自然语言处理领域了解不够深入，深度学习中涉及到众多复杂的数学公式，对算法原理一知半解，只能做到模型应用和调参的地步，对后期想要优化结果造成了困难。
2. 实验室没人有这方面的经验，所有的东西都需要自行摸索，导致进度慢且效果不佳。
3. 尝试过基于统计的方法，仅使用条件随机场 (CRF) 方法进行实体识别，但该方法对选择特征模板有较大的依赖，且目前也没有模板选择的固定方式，针对该数据集的特征模板泛化能力较低，所以后来还是选择了能够自动抽取特征的深度学习方法。 也做了对比试验，因为没有较好的特征模板，用 Bi-LSTM-CRF 方法更有
4. 没有比较完善的外部字典。

**优化方案：**
自己提出一种基于外部字典对得到的识别结果进一步优化的方法，对药品的提升较大，f1 提升了 4.62%。  
在得到最终的提交结果 submission 后，根据每个原始文件和每条提交结果，结合外部字典来优化提交结果。优化药物和手术两类实体。  
1.	对每一个原始文本 txtoriginal，判断字典中的每个词是否在原始文本中存在
2.	不存在，不管
3.	存在：获取该词的所有起始位置 start，结束位置 end（该词在原始文本中可能出现多次， start 和 end 是 list，记录所有位置）
	- 若字典中的词是 submission 中词的子串：仍用 subimssion 中的词
	- 若 submission 中的词是字典中词的子串：对该词的每个位置，删除原来的词，并将字典中的词添加到最终提交结果中（词，start，end，categroy）
	- 字典中的词与 submission 中词无重叠位置，直接将该词添加到最终提交结果中
4.	遍历完所有原始文本后，得到新的提交结果 submission_new


### 临床医学课程-知识主题图谱构建
挖掘临床医学 14 门专业主干课程的课程-章节-主题之间的关系
1. 数据预处理，收集课程资料，把 ppt、word 等按照章节转为文本，爬取 sinomed 的主题导航作为医学分词词典，然后用 jieba 包分词，并去停用词，得到主题挖掘的输入文本
2. 用 LDA 主题模型获取每个文本的主题词，通过困惑度计算确定最佳主题数。 LDA 方法的 gibbs 抽样是个随机过程，每次运行的结果可能会有细微差异，因此我们经过多次实验，把每次新增的词加到之前的主题词中，直到不再加入新词位置。挖掘出的词可能含有非医学词汇，需要人工筛选
3. 用关联规则 Apriori 算法计算主题词之间的关联，通过得到的可信度来判断词对间的关系。我们定义了三种关系：基础、进阶和同级关系。计算 confidence(A->B) 和 confidence(B->A)，如果相等就是同级；前者大，则 A 是 B 的基础， B 是 A 的进阶，因为 A 对 B 出现的影响大于 B 对 A 出现的影响程度。
4. 后面还有一些计算章节间的关联、课程间的关联以及系统可视化是别的同学负责。

**LDA 算法**  
词袋模型	

**遇到的问题**
文本比较大的话，数据处理的速度比较慢
解决方法：
采用多进程 multiprocess

## 实习经历
### 百纳：测试实习生
做的是一个桌面应用 Clauncher，可以更换主题，切换桌面，天气、时间、墙纸、文件夹等的功能。  
前期主要都在做APP的功能测试、编写测试用例等工作；  
性能测试：内存占用用 eclipse 查看
- 获取内存使用信息 adb shell dumpsys meminfo 包名
- 电量分析：  
```html
adb shell dumpsys batterystats --enable full-wake-history  
adb shell dumpsys batterystats --reset  
adb shell dumpsys batterystats --disable full-wake-history   
adb bugreport > bugreport.txt  
分析地址： http://172.18.255.73:19998/
```
抓包修改灰度： 使用 fiddler 抓包，找到请求的地址及返回的信息，在本地保存并修改，比如将一个灰度改为 False，测试灰度开关是否能够有效使用

后面接触了自动化测试，当时公司希望尝试自动化测试，然后分配我和另一个正式员工一起搭建自动化测试框架。
Appium+python搭建  
selenium 是专门做 web 端的自动化测试工具，appium 是手机 app 端的自动化，它继承了 webdriver (即selenium2)  
使用 PageObject 设计模式，实现测试用例与业务逻辑分开，方便后期维护，减少代码冗余，提高代码可读性。

1. 使用 yaml 写测试用例，只需要告诉在对哪个元素进行什么操作
2. 实现基本方法，安装卸载 app、获取 apk 信息、获取测试设备基本信息
2. 实现基本元素操作，如滑动、点击、放大、缩小等
3. 使用 HTMLTestRunner 显示测试报告，暂时只有通过的测试用例数

### 平时主要做什么？
实验室主要是做医疗健康领域的数据挖掘与知识组织服务，我主要是做一些数据处理、主题挖掘、实体识别的工作

